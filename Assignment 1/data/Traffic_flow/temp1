import numpy as np
from __future__ import print_function
from timeit import default_timer as timer
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report
from sklearn.model_selection import StratifiedKFold, KFold
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler, Normalizer

import pandas as pd

random_seed = 5432363

# Load data
train = pd.read_csv("data/Traffic_flow//train.csv")
test = pd.read_csv("data/Traffic_flow/test.csv")

del train['index']
del test['index']

Y = train['Segment23_(t+1)']
Y.describe()

# Feature Selection/Extraction
def extract(data):
    return data.iloc[:, data.shape[1]-1].values, data.iloc[:, range(0, data.shape[1]-1)].values

def row_normalization(data):
    return data.loc[:,:].div(data.sum(axis=1), axis=0).values


y = train.iloc[:, train.shape[1]-1].values
x_d = train.iloc[:, range(0, train.shape[1]-1)]
x = x_d
row_normal = Normalizer(norm='l1')
x = row_normal.fit_transform(x_d.values)
scaler = StandardScaler()
scaler.fit(x)
x_std = scaler.transform(x)
pca = PCA(n_components=.99999999)
pca.fit(x_std)
pca.explained_variance_ratio_.cumsum()
X_train = pca.transform(x_std)
y_train = y 
y_test = test.iloc[:, test.shape[1]-1].values
X_test = pca.transform(scaler.transform(row_normal.fit_transform(test.iloc[:, range(0, test.shape[1]-1)])))

# Normalization/Standardization


# Cross Validation
kf  = KFold(n_splits=5, random_state=random_seed)

# Hyperparameter Space
tuned_parameters = {
        "Ridge": [{'fit_intercept': [True, False], 'alpha': np.logspace(0, -5, num=3)}],
        "LM" : [{"fit_intercept": [True, False]}]
}
score = 'neg_median_absolute_error' # 

# Models
models = {
    "LM": LinearRegression(), "Ridge": Ridge(solver='lsqr', max_iter = 9999)
}

# train/test 
results = {}
result = {}
for key, model in models.iteritems():
    print("# Staring fittimg model of %s" % key)
    print()
    
    #y_train, X_train = extract(train)
    print("# Tuning hyper-parameters for %s" % score)
    print()
    start = time.time()
    clf = GridSearchCV(model, tuned_parameters[key], cv=kf, 
                       scoring=score)
    clf.fit(X_train, y_train)
    end = time.time()
    fitting_time = end - start
    
    print("Best parameters set found on train set:")
    print()
    print(clf.best_params_)
    print()
    print("Grid scores on train set:")
    print()
    means = clf.cv_results_['mean_test_score']
    stds = clf.cv_results_['std_test_score']
    for mean, std, params in zip(means, stds, clf.cv_results_['params']):
        print("%0.3f (+/-%0.03f) for %r"
              % (mean, std * 2, params))
    print()
    
    print("Test Set Report:")
    print()
    #y_test, X_test = extract(test)
    y_true, y_pred = y_test, clf.predict(X_test)
    print("R-Square: the % of information explain by the fitted target variable: ")
    print(mean_squared_error(y_true, y_pred))
    print()
    
    # Attach result
    m1 = clf.best_estimator_
    res = pd.DataFrame(m1.coef_, columns=["weight"])
    #res["var_name"] = train.columns[:-1]
    #res.to_csv("data/Traffic_flow/%s_coef.csv" % key, index=False)

vec_coef = clf.best_estimator_.coef_
comps = ["comp_" + str(num) for num in range(1, len(vec_coef) + 1)]
coefsd = pd.DataFrame(vec_coef, columns=['coef'])
coefsd['comps'] = comps
coefsd.to_csv("data/Traffic_flow/pc_ridge_regression.csv", index=False)

loadings = pca.components_.T * np.sqrt(pca.explained_variance_)
loadsd = pd.DataFrame(loadings, columns=comps)
loadsd['vars'] = train.columns[0:450]
loadsd.to_csv("data/Traffic_flow/pc_ridge_reg_loadings.csv", index=False)



